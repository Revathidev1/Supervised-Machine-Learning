{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yivFOFdOWipi"
   },
   "source": [
    "# Principal component analysis\n",
    "Why is PCA important?\n",
    "* Reduce computational time\n",
    "* Reduce cost\n",
    "* Preventing overfitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkJ4ibAzWipk"
   },
   "source": [
    "## Create dataset\n",
    "The purpose of this notebook is to look at PCA, so here we won't go into great detail about creating the dataset. But we'll leave it here, as opposed to just creating a CSV, as some of you maybe interested in the process. To create the dataset we used [make_classification()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), which is a SKLearn funtion that allows us to create dummy data to test ML models, stating how many relevant features, irrelevant features, duplicate features, etc... we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d-7uNoe_Wipl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# NP equivilant of random state\n",
    "np.random.seed(123) #The np. random. seed function provides an input for the pseudo-random number generator in Python.\n",
    "\n",
    "# Return numbers spaced evenly on a log scale\n",
    "# Gives the features different scales and makes a more interesting dataset\n",
    "scale_values = np.logspace(1, 5, num=500)\n",
    "\n",
    "# Create the X and y values for the DataFrame\n",
    "X, y = make_classification(n_samples=5000, \n",
    "                           n_features=500, \n",
    "                           n_informative=280,\n",
    "                           n_redundant=180, \n",
    "                           n_repeated=3, \n",
    "                           n_classes=6, \n",
    "                           flip_y=0.1,\n",
    "                           weights=[0.1, 0.2, 0.15, 0.25, 0.05], \n",
    "                           n_clusters_per_class=1, \n",
    "                           scale = scale_values, \n",
    "                           random_state=42)\n",
    "\n",
    "# Make the created values into DataFrames\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "# Rename the columns \n",
    "X = X.add_prefix(\"feature_\")\n",
    "y.rename(columns={0:\"label\"}, inplace=True)\n",
    "\n",
    "# Bring X and y together to view our DF as a whole\n",
    "codealong_df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1661849041977,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "5Xr5pQYtWipm",
    "outputId": "b4a8d8b6-1ee5-496f-84cc-ffb5d546c370"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fa969fa3-ddf7-47de-a223-86af27eb090c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_491</th>\n",
       "      <th>feature_492</th>\n",
       "      <th>feature_493</th>\n",
       "      <th>feature_494</th>\n",
       "      <th>feature_495</th>\n",
       "      <th>feature_496</th>\n",
       "      <th>feature_497</th>\n",
       "      <th>feature_498</th>\n",
       "      <th>feature_499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>546.461786</td>\n",
       "      <td>183.133455</td>\n",
       "      <td>-1150.019904</td>\n",
       "      <td>5298.050018</td>\n",
       "      <td>7.500523</td>\n",
       "      <td>-12686.970903</td>\n",
       "      <td>-112.493055</td>\n",
       "      <td>-6454.026044</td>\n",
       "      <td>531.516576</td>\n",
       "      <td>8286.286189</td>\n",
       "      <td>...</td>\n",
       "      <td>84825.221561</td>\n",
       "      <td>9.113082e+04</td>\n",
       "      <td>250071.359242</td>\n",
       "      <td>-2179.913994</td>\n",
       "      <td>1.735737e+06</td>\n",
       "      <td>-682.006209</td>\n",
       "      <td>5.650028e+05</td>\n",
       "      <td>77440.968239</td>\n",
       "      <td>141.732437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.181234</td>\n",
       "      <td>-29.869580</td>\n",
       "      <td>795.332340</td>\n",
       "      <td>8244.577935</td>\n",
       "      <td>-64.074786</td>\n",
       "      <td>-19420.478839</td>\n",
       "      <td>-238.176417</td>\n",
       "      <td>3647.286876</td>\n",
       "      <td>182.115829</td>\n",
       "      <td>20722.386033</td>\n",
       "      <td>...</td>\n",
       "      <td>-114272.011298</td>\n",
       "      <td>8.881889e+05</td>\n",
       "      <td>937548.602218</td>\n",
       "      <td>5918.908160</td>\n",
       "      <td>3.744031e+06</td>\n",
       "      <td>39.411762</td>\n",
       "      <td>-2.249651e+06</td>\n",
       "      <td>-67770.592700</td>\n",
       "      <td>-585.884028</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-147.513125</td>\n",
       "      <td>281.080058</td>\n",
       "      <td>-1222.085313</td>\n",
       "      <td>-6849.251819</td>\n",
       "      <td>-55.386172</td>\n",
       "      <td>3319.185198</td>\n",
       "      <td>-327.471273</td>\n",
       "      <td>12314.675892</td>\n",
       "      <td>-5.609710</td>\n",
       "      <td>14339.872593</td>\n",
       "      <td>...</td>\n",
       "      <td>887342.520120</td>\n",
       "      <td>-4.062938e+05</td>\n",
       "      <td>-248168.834620</td>\n",
       "      <td>-7958.639803</td>\n",
       "      <td>-4.361475e+06</td>\n",
       "      <td>-257.724275</td>\n",
       "      <td>3.107987e+05</td>\n",
       "      <td>50104.604844</td>\n",
       "      <td>-225.926753</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.062226</td>\n",
       "      <td>-87.201281</td>\n",
       "      <td>-83.549423</td>\n",
       "      <td>-177.823199</td>\n",
       "      <td>-144.197687</td>\n",
       "      <td>-16616.398077</td>\n",
       "      <td>30.904988</td>\n",
       "      <td>-994.430982</td>\n",
       "      <td>-418.581383</td>\n",
       "      <td>2179.844249</td>\n",
       "      <td>...</td>\n",
       "      <td>-286938.774096</td>\n",
       "      <td>-2.493297e+06</td>\n",
       "      <td>-58026.544280</td>\n",
       "      <td>7673.429635</td>\n",
       "      <td>-3.175762e+05</td>\n",
       "      <td>1339.701934</td>\n",
       "      <td>-4.014052e+05</td>\n",
       "      <td>9414.605559</td>\n",
       "      <td>510.005904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-222.887856</td>\n",
       "      <td>-128.185634</td>\n",
       "      <td>-1054.410539</td>\n",
       "      <td>-4039.340623</td>\n",
       "      <td>113.384258</td>\n",
       "      <td>-100.535098</td>\n",
       "      <td>-225.664434</td>\n",
       "      <td>-4691.428044</td>\n",
       "      <td>-212.522834</td>\n",
       "      <td>-25966.053643</td>\n",
       "      <td>...</td>\n",
       "      <td>338399.469401</td>\n",
       "      <td>-3.899652e+06</td>\n",
       "      <td>501438.458669</td>\n",
       "      <td>1375.408163</td>\n",
       "      <td>-4.624358e+06</td>\n",
       "      <td>-977.193223</td>\n",
       "      <td>7.671711e+05</td>\n",
       "      <td>3707.134463</td>\n",
       "      <td>378.345297</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>78.668528</td>\n",
       "      <td>-775.181668</td>\n",
       "      <td>545.889422</td>\n",
       "      <td>-17595.223712</td>\n",
       "      <td>-72.495203</td>\n",
       "      <td>-1583.053081</td>\n",
       "      <td>464.448349</td>\n",
       "      <td>16655.273820</td>\n",
       "      <td>-491.945477</td>\n",
       "      <td>444.578432</td>\n",
       "      <td>...</td>\n",
       "      <td>46375.791491</td>\n",
       "      <td>-4.632005e+04</td>\n",
       "      <td>-126664.153158</td>\n",
       "      <td>-4627.018783</td>\n",
       "      <td>5.914249e+05</td>\n",
       "      <td>-881.295595</td>\n",
       "      <td>-1.226826e+06</td>\n",
       "      <td>69817.668526</td>\n",
       "      <td>541.923404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>181.066286</td>\n",
       "      <td>352.242055</td>\n",
       "      <td>-484.148117</td>\n",
       "      <td>13461.733060</td>\n",
       "      <td>-65.644050</td>\n",
       "      <td>-2316.520476</td>\n",
       "      <td>306.623786</td>\n",
       "      <td>7693.974752</td>\n",
       "      <td>-287.564454</td>\n",
       "      <td>11576.070270</td>\n",
       "      <td>...</td>\n",
       "      <td>-462896.607253</td>\n",
       "      <td>4.703504e+05</td>\n",
       "      <td>586434.268922</td>\n",
       "      <td>-4221.100267</td>\n",
       "      <td>5.310497e+06</td>\n",
       "      <td>165.210784</td>\n",
       "      <td>8.186926e+03</td>\n",
       "      <td>39654.692843</td>\n",
       "      <td>-239.529416</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>445.825091</td>\n",
       "      <td>-487.705128</td>\n",
       "      <td>-273.265368</td>\n",
       "      <td>-6435.648183</td>\n",
       "      <td>-57.790540</td>\n",
       "      <td>-7324.035293</td>\n",
       "      <td>-244.342090</td>\n",
       "      <td>-1038.213786</td>\n",
       "      <td>-211.770883</td>\n",
       "      <td>-474.550723</td>\n",
       "      <td>...</td>\n",
       "      <td>163373.129150</td>\n",
       "      <td>-1.304860e+06</td>\n",
       "      <td>398838.642808</td>\n",
       "      <td>-5450.509483</td>\n",
       "      <td>4.321766e+06</td>\n",
       "      <td>-855.627182</td>\n",
       "      <td>-9.703374e+04</td>\n",
       "      <td>77562.715617</td>\n",
       "      <td>25.140248</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-373.018228</td>\n",
       "      <td>31.984627</td>\n",
       "      <td>451.227077</td>\n",
       "      <td>11040.189704</td>\n",
       "      <td>186.659580</td>\n",
       "      <td>4468.325278</td>\n",
       "      <td>-216.528306</td>\n",
       "      <td>-3431.999024</td>\n",
       "      <td>-212.712351</td>\n",
       "      <td>-2364.479124</td>\n",
       "      <td>...</td>\n",
       "      <td>-168802.142232</td>\n",
       "      <td>1.098234e+06</td>\n",
       "      <td>122472.101832</td>\n",
       "      <td>2927.367347</td>\n",
       "      <td>4.187729e+06</td>\n",
       "      <td>-697.771295</td>\n",
       "      <td>5.668534e+05</td>\n",
       "      <td>140972.121248</td>\n",
       "      <td>43.741397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-317.714744</td>\n",
       "      <td>-212.304162</td>\n",
       "      <td>-273.734146</td>\n",
       "      <td>15993.362409</td>\n",
       "      <td>82.177416</td>\n",
       "      <td>54.667200</td>\n",
       "      <td>319.674223</td>\n",
       "      <td>-1854.659249</td>\n",
       "      <td>36.880362</td>\n",
       "      <td>12560.004680</td>\n",
       "      <td>...</td>\n",
       "      <td>-147192.382173</td>\n",
       "      <td>2.808729e+06</td>\n",
       "      <td>451478.133168</td>\n",
       "      <td>182.617477</td>\n",
       "      <td>1.420744e+06</td>\n",
       "      <td>215.398687</td>\n",
       "      <td>1.171170e+06</td>\n",
       "      <td>-64664.895010</td>\n",
       "      <td>156.351589</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 501 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa969fa3-ddf7-47de-a223-86af27eb090c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fa969fa3-ddf7-47de-a223-86af27eb090c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fa969fa3-ddf7-47de-a223-86af27eb090c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       feature_0   feature_1    feature_2     feature_3   feature_4  \\\n",
       "0     546.461786  183.133455 -1150.019904   5298.050018    7.500523   \n",
       "1     115.181234  -29.869580   795.332340   8244.577935  -64.074786   \n",
       "2    -147.513125  281.080058 -1222.085313  -6849.251819  -55.386172   \n",
       "3      91.062226  -87.201281   -83.549423   -177.823199 -144.197687   \n",
       "4    -222.887856 -128.185634 -1054.410539  -4039.340623  113.384258   \n",
       "...          ...         ...          ...           ...         ...   \n",
       "4995   78.668528 -775.181668   545.889422 -17595.223712  -72.495203   \n",
       "4996  181.066286  352.242055  -484.148117  13461.733060  -65.644050   \n",
       "4997  445.825091 -487.705128  -273.265368  -6435.648183  -57.790540   \n",
       "4998 -373.018228   31.984627   451.227077  11040.189704  186.659580   \n",
       "4999 -317.714744 -212.304162  -273.734146  15993.362409   82.177416   \n",
       "\n",
       "         feature_5   feature_6     feature_7   feature_8     feature_9  ...  \\\n",
       "0    -12686.970903 -112.493055  -6454.026044  531.516576   8286.286189  ...   \n",
       "1    -19420.478839 -238.176417   3647.286876  182.115829  20722.386033  ...   \n",
       "2      3319.185198 -327.471273  12314.675892   -5.609710  14339.872593  ...   \n",
       "3    -16616.398077   30.904988   -994.430982 -418.581383   2179.844249  ...   \n",
       "4      -100.535098 -225.664434  -4691.428044 -212.522834 -25966.053643  ...   \n",
       "...            ...         ...           ...         ...           ...  ...   \n",
       "4995  -1583.053081  464.448349  16655.273820 -491.945477    444.578432  ...   \n",
       "4996  -2316.520476  306.623786   7693.974752 -287.564454  11576.070270  ...   \n",
       "4997  -7324.035293 -244.342090  -1038.213786 -211.770883   -474.550723  ...   \n",
       "4998   4468.325278 -216.528306  -3431.999024 -212.712351  -2364.479124  ...   \n",
       "4999     54.667200  319.674223  -1854.659249   36.880362  12560.004680  ...   \n",
       "\n",
       "        feature_491   feature_492    feature_493  feature_494   feature_495  \\\n",
       "0      84825.221561  9.113082e+04  250071.359242 -2179.913994  1.735737e+06   \n",
       "1    -114272.011298  8.881889e+05  937548.602218  5918.908160  3.744031e+06   \n",
       "2     887342.520120 -4.062938e+05 -248168.834620 -7958.639803 -4.361475e+06   \n",
       "3    -286938.774096 -2.493297e+06  -58026.544280  7673.429635 -3.175762e+05   \n",
       "4     338399.469401 -3.899652e+06  501438.458669  1375.408163 -4.624358e+06   \n",
       "...             ...           ...            ...          ...           ...   \n",
       "4995   46375.791491 -4.632005e+04 -126664.153158 -4627.018783  5.914249e+05   \n",
       "4996 -462896.607253  4.703504e+05  586434.268922 -4221.100267  5.310497e+06   \n",
       "4997  163373.129150 -1.304860e+06  398838.642808 -5450.509483  4.321766e+06   \n",
       "4998 -168802.142232  1.098234e+06  122472.101832  2927.367347  4.187729e+06   \n",
       "4999 -147192.382173  2.808729e+06  451478.133168   182.617477  1.420744e+06   \n",
       "\n",
       "      feature_496   feature_497    feature_498  feature_499  label  \n",
       "0     -682.006209  5.650028e+05   77440.968239   141.732437      0  \n",
       "1       39.411762 -2.249651e+06  -67770.592700  -585.884028      5  \n",
       "2     -257.724275  3.107987e+05   50104.604844  -225.926753      5  \n",
       "3     1339.701934 -4.014052e+05    9414.605559   510.005904      2  \n",
       "4     -977.193223  7.671711e+05    3707.134463   378.345297      3  \n",
       "...           ...           ...            ...          ...    ...  \n",
       "4995  -881.295595 -1.226826e+06   69817.668526   541.923404      0  \n",
       "4996   165.210784  8.186926e+03   39654.692843  -239.529416      3  \n",
       "4997  -855.627182 -9.703374e+04   77562.715617    25.140248      4  \n",
       "4998  -697.771295  5.668534e+05  140972.121248    43.741397      1  \n",
       "4999   215.398687  1.171170e+06  -64664.895010   156.351589      3  \n",
       "\n",
       "[5000 rows x 501 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codealong_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSG5uE-NWipn"
   },
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_2Rvr07sWipn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(codealong_df,\n",
    "                                       test_size=0.2,\n",
    "                                       random_state=123)\n",
    "\n",
    "X_train = train_set.drop(columns=\"label\").copy()\n",
    "y_train = train_set[\"label\"].copy()\n",
    "\n",
    "X_test = test_set.drop(columns=\"label\").copy()\n",
    "y_test = test_set[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_490</th>\n",
       "      <th>feature_491</th>\n",
       "      <th>feature_492</th>\n",
       "      <th>feature_493</th>\n",
       "      <th>feature_494</th>\n",
       "      <th>feature_495</th>\n",
       "      <th>feature_496</th>\n",
       "      <th>feature_497</th>\n",
       "      <th>feature_498</th>\n",
       "      <th>feature_499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>-74.242529</td>\n",
       "      <td>831.036997</td>\n",
       "      <td>101.384884</td>\n",
       "      <td>-2268.451380</td>\n",
       "      <td>-155.187878</td>\n",
       "      <td>2434.248497</td>\n",
       "      <td>56.822238</td>\n",
       "      <td>9746.520020</td>\n",
       "      <td>-470.596106</td>\n",
       "      <td>-608.197920</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060915e+06</td>\n",
       "      <td>-229815.073179</td>\n",
       "      <td>-1.104602e+06</td>\n",
       "      <td>-861648.941868</td>\n",
       "      <td>1370.971923</td>\n",
       "      <td>1.861978e+06</td>\n",
       "      <td>-750.219909</td>\n",
       "      <td>-1.883157e+06</td>\n",
       "      <td>-401.937583</td>\n",
       "      <td>-83.808604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>22.280750</td>\n",
       "      <td>-675.948581</td>\n",
       "      <td>-62.597755</td>\n",
       "      <td>-12248.271844</td>\n",
       "      <td>84.815854</td>\n",
       "      <td>-15855.927193</td>\n",
       "      <td>-295.410694</td>\n",
       "      <td>-5804.049602</td>\n",
       "      <td>-274.169020</td>\n",
       "      <td>1739.355908</td>\n",
       "      <td>...</td>\n",
       "      <td>4.470712e+06</td>\n",
       "      <td>-223706.392750</td>\n",
       "      <td>1.459442e+06</td>\n",
       "      <td>225627.011326</td>\n",
       "      <td>-3532.869185</td>\n",
       "      <td>9.121104e+05</td>\n",
       "      <td>-892.377755</td>\n",
       "      <td>5.691612e+05</td>\n",
       "      <td>22085.107143</td>\n",
       "      <td>-72.946126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>-5.478200</td>\n",
       "      <td>-297.961243</td>\n",
       "      <td>-1081.956850</td>\n",
       "      <td>-5325.165173</td>\n",
       "      <td>-225.270450</td>\n",
       "      <td>-9522.983121</td>\n",
       "      <td>110.166186</td>\n",
       "      <td>1935.669933</td>\n",
       "      <td>293.768939</td>\n",
       "      <td>5091.542644</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.392081e+05</td>\n",
       "      <td>-487582.757118</td>\n",
       "      <td>3.990345e+06</td>\n",
       "      <td>-96641.719250</td>\n",
       "      <td>-12807.878633</td>\n",
       "      <td>3.214942e+06</td>\n",
       "      <td>-168.021533</td>\n",
       "      <td>3.327864e+04</td>\n",
       "      <td>-83394.472147</td>\n",
       "      <td>-650.442987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>-147.435600</td>\n",
       "      <td>-4.723274</td>\n",
       "      <td>400.155207</td>\n",
       "      <td>-3157.206769</td>\n",
       "      <td>100.959492</td>\n",
       "      <td>23375.565301</td>\n",
       "      <td>65.193717</td>\n",
       "      <td>-2903.474255</td>\n",
       "      <td>-467.037569</td>\n",
       "      <td>715.274918</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.732626e+06</td>\n",
       "      <td>509878.717016</td>\n",
       "      <td>-1.535077e+06</td>\n",
       "      <td>-312914.152611</td>\n",
       "      <td>2327.932509</td>\n",
       "      <td>-1.200866e+06</td>\n",
       "      <td>-1368.693506</td>\n",
       "      <td>-4.859136e+05</td>\n",
       "      <td>-1672.257626</td>\n",
       "      <td>-131.453337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>335.803128</td>\n",
       "      <td>-180.007655</td>\n",
       "      <td>866.991035</td>\n",
       "      <td>-4161.386211</td>\n",
       "      <td>-70.521044</td>\n",
       "      <td>-3575.596488</td>\n",
       "      <td>-79.197238</td>\n",
       "      <td>-3432.517004</td>\n",
       "      <td>-406.159483</td>\n",
       "      <td>-16027.481890</td>\n",
       "      <td>...</td>\n",
       "      <td>1.161319e+06</td>\n",
       "      <td>127718.522177</td>\n",
       "      <td>-5.252095e+05</td>\n",
       "      <td>-682442.313297</td>\n",
       "      <td>-2281.266008</td>\n",
       "      <td>-3.669074e+06</td>\n",
       "      <td>1153.248194</td>\n",
       "      <td>1.297570e+06</td>\n",
       "      <td>-91341.403217</td>\n",
       "      <td>-180.491358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>235.461595</td>\n",
       "      <td>251.767515</td>\n",
       "      <td>-567.258640</td>\n",
       "      <td>5343.771879</td>\n",
       "      <td>-53.210463</td>\n",
       "      <td>3572.908057</td>\n",
       "      <td>-302.083329</td>\n",
       "      <td>4438.749509</td>\n",
       "      <td>-82.396857</td>\n",
       "      <td>1416.998023</td>\n",
       "      <td>...</td>\n",
       "      <td>7.437962e+05</td>\n",
       "      <td>418799.807762</td>\n",
       "      <td>-2.081853e+06</td>\n",
       "      <td>-736388.113827</td>\n",
       "      <td>1861.870027</td>\n",
       "      <td>8.292883e+04</td>\n",
       "      <td>-1331.195514</td>\n",
       "      <td>4.759243e+05</td>\n",
       "      <td>-38531.453863</td>\n",
       "      <td>-313.099751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>-198.911987</td>\n",
       "      <td>-77.113479</td>\n",
       "      <td>-939.938902</td>\n",
       "      <td>2745.147092</td>\n",
       "      <td>-98.042544</td>\n",
       "      <td>13405.271111</td>\n",
       "      <td>-237.774586</td>\n",
       "      <td>9613.833383</td>\n",
       "      <td>45.896404</td>\n",
       "      <td>2874.480228</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836354e+06</td>\n",
       "      <td>-138989.428299</td>\n",
       "      <td>-3.322472e+06</td>\n",
       "      <td>387714.811744</td>\n",
       "      <td>-7606.164562</td>\n",
       "      <td>-5.965724e+06</td>\n",
       "      <td>51.200103</td>\n",
       "      <td>7.271859e+05</td>\n",
       "      <td>-25883.242535</td>\n",
       "      <td>148.209467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>-115.869023</td>\n",
       "      <td>177.061707</td>\n",
       "      <td>1132.232178</td>\n",
       "      <td>656.260020</td>\n",
       "      <td>-167.038859</td>\n",
       "      <td>6513.218039</td>\n",
       "      <td>434.268280</td>\n",
       "      <td>-4322.632831</td>\n",
       "      <td>333.512682</td>\n",
       "      <td>-7886.500899</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.367374e+05</td>\n",
       "      <td>311579.851628</td>\n",
       "      <td>6.823776e+05</td>\n",
       "      <td>-49106.866894</td>\n",
       "      <td>-1974.733535</td>\n",
       "      <td>1.079378e+06</td>\n",
       "      <td>-372.062503</td>\n",
       "      <td>-3.714764e+05</td>\n",
       "      <td>3873.536091</td>\n",
       "      <td>296.762231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>-761.265582</td>\n",
       "      <td>-424.283511</td>\n",
       "      <td>-391.446535</td>\n",
       "      <td>13377.762820</td>\n",
       "      <td>-72.844764</td>\n",
       "      <td>-13270.259219</td>\n",
       "      <td>384.970769</td>\n",
       "      <td>-1404.750168</td>\n",
       "      <td>14.725279</td>\n",
       "      <td>-5345.442082</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.893472e+05</td>\n",
       "      <td>411344.267317</td>\n",
       "      <td>2.650983e+05</td>\n",
       "      <td>22138.917816</td>\n",
       "      <td>1683.646088</td>\n",
       "      <td>6.655064e+06</td>\n",
       "      <td>-1.608505</td>\n",
       "      <td>-5.622096e+05</td>\n",
       "      <td>-49358.606709</td>\n",
       "      <td>-398.474465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>132.403397</td>\n",
       "      <td>243.502415</td>\n",
       "      <td>676.776329</td>\n",
       "      <td>11911.708729</td>\n",
       "      <td>20.559956</td>\n",
       "      <td>-18956.378631</td>\n",
       "      <td>-546.864746</td>\n",
       "      <td>-7603.379066</td>\n",
       "      <td>128.550512</td>\n",
       "      <td>22588.094135</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.590628e+06</td>\n",
       "      <td>266270.661470</td>\n",
       "      <td>-2.400841e+06</td>\n",
       "      <td>310070.887493</td>\n",
       "      <td>2956.920568</td>\n",
       "      <td>1.430850e+06</td>\n",
       "      <td>714.640909</td>\n",
       "      <td>-6.747498e+05</td>\n",
       "      <td>70906.618008</td>\n",
       "      <td>371.312247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_0   feature_1    feature_2     feature_3   feature_4  \\\n",
       "1863  -74.242529  831.036997   101.384884  -2268.451380 -155.187878   \n",
       "420    22.280750 -675.948581   -62.597755 -12248.271844   84.815854   \n",
       "3260   -5.478200 -297.961243 -1081.956850  -5325.165173 -225.270450   \n",
       "742  -147.435600   -4.723274   400.155207  -3157.206769  100.959492   \n",
       "4809  335.803128 -180.007655   866.991035  -4161.386211  -70.521044   \n",
       "...          ...         ...          ...           ...         ...   \n",
       "1593  235.461595  251.767515  -567.258640   5343.771879  -53.210463   \n",
       "4060 -198.911987  -77.113479  -939.938902   2745.147092  -98.042544   \n",
       "1346 -115.869023  177.061707  1132.232178    656.260020 -167.038859   \n",
       "3454 -761.265582 -424.283511  -391.446535  13377.762820  -72.844764   \n",
       "3582  132.403397  243.502415   676.776329  11911.708729   20.559956   \n",
       "\n",
       "         feature_5   feature_6    feature_7   feature_8     feature_9  ...  \\\n",
       "1863   2434.248497   56.822238  9746.520020 -470.596106   -608.197920  ...   \n",
       "420  -15855.927193 -295.410694 -5804.049602 -274.169020   1739.355908  ...   \n",
       "3260  -9522.983121  110.166186  1935.669933  293.768939   5091.542644  ...   \n",
       "742   23375.565301   65.193717 -2903.474255 -467.037569    715.274918  ...   \n",
       "4809  -3575.596488  -79.197238 -3432.517004 -406.159483 -16027.481890  ...   \n",
       "...            ...         ...          ...         ...           ...  ...   \n",
       "1593   3572.908057 -302.083329  4438.749509  -82.396857   1416.998023  ...   \n",
       "4060  13405.271111 -237.774586  9613.833383   45.896404   2874.480228  ...   \n",
       "1346   6513.218039  434.268280 -4322.632831  333.512682  -7886.500899  ...   \n",
       "3454 -13270.259219  384.970769 -1404.750168   14.725279  -5345.442082  ...   \n",
       "3582 -18956.378631 -546.864746 -7603.379066  128.550512  22588.094135  ...   \n",
       "\n",
       "       feature_490    feature_491   feature_492    feature_493   feature_494  \\\n",
       "1863 -1.060915e+06 -229815.073179 -1.104602e+06 -861648.941868   1370.971923   \n",
       "420   4.470712e+06 -223706.392750  1.459442e+06  225627.011326  -3532.869185   \n",
       "3260 -6.392081e+05 -487582.757118  3.990345e+06  -96641.719250 -12807.878633   \n",
       "742  -2.732626e+06  509878.717016 -1.535077e+06 -312914.152611   2327.932509   \n",
       "4809  1.161319e+06  127718.522177 -5.252095e+05 -682442.313297  -2281.266008   \n",
       "...            ...            ...           ...            ...           ...   \n",
       "1593  7.437962e+05  418799.807762 -2.081853e+06 -736388.113827   1861.870027   \n",
       "4060  1.836354e+06 -138989.428299 -3.322472e+06  387714.811744  -7606.164562   \n",
       "1346 -3.367374e+05  311579.851628  6.823776e+05  -49106.866894  -1974.733535   \n",
       "3454 -2.893472e+05  411344.267317  2.650983e+05   22138.917816   1683.646088   \n",
       "3582 -1.590628e+06  266270.661470 -2.400841e+06  310070.887493   2956.920568   \n",
       "\n",
       "       feature_495  feature_496   feature_497   feature_498  feature_499  \n",
       "1863  1.861978e+06  -750.219909 -1.883157e+06   -401.937583   -83.808604  \n",
       "420   9.121104e+05  -892.377755  5.691612e+05  22085.107143   -72.946126  \n",
       "3260  3.214942e+06  -168.021533  3.327864e+04 -83394.472147  -650.442987  \n",
       "742  -1.200866e+06 -1368.693506 -4.859136e+05  -1672.257626  -131.453337  \n",
       "4809 -3.669074e+06  1153.248194  1.297570e+06 -91341.403217  -180.491358  \n",
       "...            ...          ...           ...           ...          ...  \n",
       "1593  8.292883e+04 -1331.195514  4.759243e+05 -38531.453863  -313.099751  \n",
       "4060 -5.965724e+06    51.200103  7.271859e+05 -25883.242535   148.209467  \n",
       "1346  1.079378e+06  -372.062503 -3.714764e+05   3873.536091   296.762231  \n",
       "3454  6.655064e+06    -1.608505 -5.622096e+05 -49358.606709  -398.474465  \n",
       "3582  1.430850e+06   714.640909 -6.747498e+05  70906.618008   371.312247  \n",
       "\n",
       "[4000 rows x 500 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhUTdxQhWipo"
   },
   "source": [
    "### Iteration 1: No PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8-Dlv9XoWipo"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hJKzgLYoGsw"
   },
   "source": [
    "To help us see the effects of PCA we will time our models.\n",
    "\n",
    "Here's a quick example of how we can time our cell and store that time as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1661849041981,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "CFyTDQe2sM1O",
    "outputId": "98cd4cab-e298-49bd-eab6-aa57436d6e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "--- 0.0 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# At the start of cell define the start variable\n",
    "start_time = time.time()\n",
    "\n",
    "# Next comes our code\n",
    "print(\"hello world\")\n",
    "\n",
    "# After the code define the end variable\n",
    "end_time = time.time()\n",
    "\n",
    "# Store the difference between the end and the start as a variable\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time_taken))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuacH3TSutld"
   },
   "source": [
    "Now, let's time our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499869,
     "status": "ok",
     "timestamp": 1661849541840,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "IRzlTUz0tv7M",
    "outputId": "89407c39-15cd-492a-d32b-0bd8a99742c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 129.96452713012695 seconds ---\n",
      "80.85% accuracy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model_pipeline = make_pipeline(StandardScaler(),\n",
    "                               KNeighborsClassifier())\n",
    "\n",
    "param_grid = {\"kneighborsclassifier__n_neighbors\": list(range(3, 30)),\n",
    "              \"kneighborsclassifier__weights\":[\"uniform\", \"distance\"],\n",
    "              \"kneighborsclassifier__p\":[1,2]}\n",
    "\n",
    "neigh1_search = RandomizedSearchCV(model_pipeline,\n",
    "                                   param_grid,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   n_iter=50,\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=123)\n",
    "\n",
    "neigh1_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_no_pca = end_time - start_time\n",
    "best_score_no_pca = neigh1_search.best_score_\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time_taken_no_pca))\n",
    "print(f\"{round(best_score_no_pca * 100, 2)}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9n6Cv53Wipp"
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50VUgxL4PAX3"
   },
   "source": [
    "### Picking the number of components 1: just choose a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QD4zNKa2Wipp"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10) # pick number of components \n",
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 477,
     "status": "ok",
     "timestamp": 1661849542305,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "47WL4CjtWipp",
    "outputId": "1b4b466c-9b61-4699-d0c2-8fb3a5f81b37",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1661849542306,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "n9jGL4XmWipp",
    "outputId": "0c17cdf9-2e4b-4672-88fc-96bf4aa9693c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.242661e+06</td>\n",
       "      <td>1.496181e+06</td>\n",
       "      <td>-3.564769e+06</td>\n",
       "      <td>3.398767e+06</td>\n",
       "      <td>4.763004e+06</td>\n",
       "      <td>3.271635e+06</td>\n",
       "      <td>-2.464158e+06</td>\n",
       "      <td>3.892005e+06</td>\n",
       "      <td>-2.647814e+06</td>\n",
       "      <td>1.399267e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.129390e+05</td>\n",
       "      <td>1.777891e+06</td>\n",
       "      <td>-4.025414e+05</td>\n",
       "      <td>2.560810e+06</td>\n",
       "      <td>-7.019266e+06</td>\n",
       "      <td>4.806393e+06</td>\n",
       "      <td>-6.368530e+06</td>\n",
       "      <td>-4.372359e+06</td>\n",
       "      <td>-8.663023e+06</td>\n",
       "      <td>4.915663e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.394974e+06</td>\n",
       "      <td>3.924064e+06</td>\n",
       "      <td>4.119066e+05</td>\n",
       "      <td>3.781304e+06</td>\n",
       "      <td>-7.707630e+06</td>\n",
       "      <td>4.166810e+06</td>\n",
       "      <td>1.389670e+06</td>\n",
       "      <td>-2.483612e+06</td>\n",
       "      <td>-1.929311e+06</td>\n",
       "      <td>1.572180e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.330068e+07</td>\n",
       "      <td>-1.486839e+06</td>\n",
       "      <td>-5.627674e+06</td>\n",
       "      <td>9.147499e+05</td>\n",
       "      <td>3.326714e+06</td>\n",
       "      <td>-1.349815e+06</td>\n",
       "      <td>6.535318e+06</td>\n",
       "      <td>1.143153e+06</td>\n",
       "      <td>1.892447e+06</td>\n",
       "      <td>-5.844793e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.363581e+06</td>\n",
       "      <td>-4.352057e+06</td>\n",
       "      <td>-1.165842e+07</td>\n",
       "      <td>-4.847896e+05</td>\n",
       "      <td>4.906166e+06</td>\n",
       "      <td>2.836528e+06</td>\n",
       "      <td>7.480845e+06</td>\n",
       "      <td>-6.179718e+06</td>\n",
       "      <td>-8.545421e+06</td>\n",
       "      <td>-1.436803e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>-2.997380e+06</td>\n",
       "      <td>1.429663e+06</td>\n",
       "      <td>-8.939501e+05</td>\n",
       "      <td>-5.618805e+06</td>\n",
       "      <td>-5.301517e+06</td>\n",
       "      <td>-4.361711e+06</td>\n",
       "      <td>-3.573981e+06</td>\n",
       "      <td>7.374122e+05</td>\n",
       "      <td>-4.336446e+06</td>\n",
       "      <td>2.545991e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>6.882406e+06</td>\n",
       "      <td>3.115047e+06</td>\n",
       "      <td>3.048198e+06</td>\n",
       "      <td>7.470975e+05</td>\n",
       "      <td>-4.381319e+06</td>\n",
       "      <td>2.949829e+06</td>\n",
       "      <td>2.128018e+06</td>\n",
       "      <td>7.375239e+05</td>\n",
       "      <td>-2.481100e+06</td>\n",
       "      <td>-7.138747e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>5.174989e+06</td>\n",
       "      <td>-3.217244e+06</td>\n",
       "      <td>2.477737e+06</td>\n",
       "      <td>-5.239851e+06</td>\n",
       "      <td>-1.719152e+06</td>\n",
       "      <td>1.128832e+06</td>\n",
       "      <td>4.139042e+06</td>\n",
       "      <td>-9.016630e+05</td>\n",
       "      <td>-2.654668e+06</td>\n",
       "      <td>3.494176e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>-4.151505e+04</td>\n",
       "      <td>1.012522e+07</td>\n",
       "      <td>3.804271e+06</td>\n",
       "      <td>3.473344e+06</td>\n",
       "      <td>-1.645494e+06</td>\n",
       "      <td>-1.089667e+06</td>\n",
       "      <td>6.712435e+06</td>\n",
       "      <td>-3.477845e+06</td>\n",
       "      <td>1.838319e+06</td>\n",
       "      <td>-3.808699e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>2.899014e+06</td>\n",
       "      <td>-4.639879e+06</td>\n",
       "      <td>-3.960842e+06</td>\n",
       "      <td>3.822061e+06</td>\n",
       "      <td>5.358039e+06</td>\n",
       "      <td>8.629260e+05</td>\n",
       "      <td>-3.324939e+06</td>\n",
       "      <td>-7.545799e+05</td>\n",
       "      <td>1.234080e+06</td>\n",
       "      <td>1.660935e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4  \\\n",
       "0     2.242661e+06  1.496181e+06 -3.564769e+06  3.398767e+06  4.763004e+06   \n",
       "1     8.129390e+05  1.777891e+06 -4.025414e+05  2.560810e+06 -7.019266e+06   \n",
       "2     5.394974e+06  3.924064e+06  4.119066e+05  3.781304e+06 -7.707630e+06   \n",
       "3    -1.330068e+07 -1.486839e+06 -5.627674e+06  9.147499e+05  3.326714e+06   \n",
       "4     7.363581e+06 -4.352057e+06 -1.165842e+07 -4.847896e+05  4.906166e+06   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3995 -2.997380e+06  1.429663e+06 -8.939501e+05 -5.618805e+06 -5.301517e+06   \n",
       "3996  6.882406e+06  3.115047e+06  3.048198e+06  7.470975e+05 -4.381319e+06   \n",
       "3997  5.174989e+06 -3.217244e+06  2.477737e+06 -5.239851e+06 -1.719152e+06   \n",
       "3998 -4.151505e+04  1.012522e+07  3.804271e+06  3.473344e+06 -1.645494e+06   \n",
       "3999  2.899014e+06 -4.639879e+06 -3.960842e+06  3.822061e+06  5.358039e+06   \n",
       "\n",
       "                 5             6             7             8             9  \n",
       "0     3.271635e+06 -2.464158e+06  3.892005e+06 -2.647814e+06  1.399267e+06  \n",
       "1     4.806393e+06 -6.368530e+06 -4.372359e+06 -8.663023e+06  4.915663e+06  \n",
       "2     4.166810e+06  1.389670e+06 -2.483612e+06 -1.929311e+06  1.572180e+06  \n",
       "3    -1.349815e+06  6.535318e+06  1.143153e+06  1.892447e+06 -5.844793e+06  \n",
       "4     2.836528e+06  7.480845e+06 -6.179718e+06 -8.545421e+06 -1.436803e+06  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "3995 -4.361711e+06 -3.573981e+06  7.374122e+05 -4.336446e+06  2.545991e+06  \n",
       "3996  2.949829e+06  2.128018e+06  7.375239e+05 -2.481100e+06 -7.138747e+05  \n",
       "3997  1.128832e+06  4.139042e+06 -9.016630e+05 -2.654668e+06  3.494176e+06  \n",
       "3998 -1.089667e+06  6.712435e+06 -3.477845e+06  1.838319e+06 -3.808699e+05  \n",
       "3999  8.629260e+05 -3.324939e+06 -7.545799e+05  1.234080e+06  1.660935e+06  \n",
       "\n",
       "[4000 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtxkGcR5Wipp"
   },
   "source": [
    "### Iteration 2: with PCA\n",
    "Now that we've reduced the number of features to 10, from 500, let's see the effects that has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43753,
     "status": "ok",
     "timestamp": 1661849586054,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "cB3B2xsBtiFp",
    "outputId": "d06f40c9-7e5f-4887-9d0e-8c6b321d8136"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 38.68808031082153 seconds ---\n",
      "29.5% accuracy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model_pipeline = make_pipeline(StandardScaler(),\n",
    "                               PCA(n_components=10),\n",
    "                               KNeighborsClassifier())\n",
    "\n",
    "param_grid = {\"kneighborsclassifier__n_neighbors\": list(range(3, 30)),\n",
    "              \"kneighborsclassifier__weights\":[\"uniform\", \"distance\"],\n",
    "              \"kneighborsclassifier__p\":[1,2]}\n",
    "\n",
    "neigh2_search = RandomizedSearchCV(model_pipeline,\n",
    "                                   param_grid,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   n_iter=50,\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=123)\n",
    "\n",
    "neigh2_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_10_pca = end_time - start_time\n",
    "best_score_10_pca = neigh2_search.best_score_\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time_taken_10_pca))\n",
    "print(f\"{round(best_score_10_pca * 100, 2)}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSJoYfPDWipq"
   },
   "source": [
    "### Picking the number of components 2: by variance\n",
    "As you saw above, if we are too heavy handed with PCA, and reduce the amount of columns too drastically, we have a massive effect on the accuracy. So, how do we know what the optimal amount of columns are?\n",
    "\n",
    "We can explore the features using PCA's `explained_variance_ratio_` attribute. This highlights the amount of variance explained by each of the selected components. In other words, this will show us how much of the total variance, as a percentage, each of the columns accounts for. \n",
    "\n",
    "We'll set `n_components` to `None` so we can explore the amount of variance of all components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1661849586414,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "biRSx_mTWipq",
    "outputId": "e7a8dff3-030f-4932-f579-859385401cdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.54, 4.85, 4.19, 4.  , 3.75, 3.52, 3.28, 3.24, 3.03, 2.83, 2.79,\n",
       "       2.5 , 2.38, 2.3 , 2.23, 2.08, 1.96, 1.88, 1.82, 1.78, 1.73, 1.66,\n",
       "       1.54, 1.47, 1.42, 1.37, 1.31, 1.24, 1.19, 1.17, 1.12, 1.09, 1.01,\n",
       "       0.96, 0.92, 0.89, 0.86, 0.81, 0.81, 0.78, 0.73, 0.69, 0.66, 0.63,\n",
       "       0.6 , 0.57, 0.56, 0.55, 0.52, 0.49, 0.46, 0.43, 0.42, 0.4 , 0.38,\n",
       "       0.37, 0.35, 0.34, 0.33, 0.31, 0.3 , 0.29, 0.28, 0.27, 0.25, 0.24,\n",
       "       0.23, 0.21, 0.21, 0.2 , 0.19, 0.19, 0.18, 0.17, 0.16, 0.15, 0.15,\n",
       "       0.14, 0.14, 0.13, 0.12, 0.12, 0.12, 0.11, 0.1 , 0.1 , 0.1 , 0.09,\n",
       "       0.08, 0.08, 0.08, 0.07, 0.07, 0.07, 0.07, 0.07, 0.06, 0.06, 0.05,\n",
       "       0.05, 0.05, 0.05, 0.05, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.03,\n",
       "       0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.02, 0.02, 0.02, 0.02,\n",
       "       0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=None)\n",
    "pca.fit(X_train)\n",
    "\n",
    "np.round(pca.explained_variance_ratio_, 4)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IP57e4Fc0t8A"
   },
   "source": [
    "Look at all of the 0's at the end, looks like we have quite a few columns that are providing our model without a lot of information.\n",
    "\n",
    "We can also visualise cumulative total of `pca.explained_variance_ratio_` to see how many of our columns are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1661849586891,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "gnRttEPaWips",
    "outputId": "27b2d8d2-547b-4e28-d3b8-99f3aa0b224c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(cumsum, label = \"Explained variance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOJ8xTWXEsDH"
   },
   "source": [
    "It's common to choose the amount of features that make up 95% of the variance. This way we are feeding our model almost the same amount of data, but reducing the number of features. The cell below calculates the number of features that make up 95% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1661849586892,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "ASaU-z4iEXYd",
    "outputId": "c4339677-c70f-43a2-9530-9ba14e824267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cumsum < 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7zmDhKoWips"
   },
   "source": [
    "### Iteration 3: PCA and variance\n",
    "In our pipeline we'll set the `n_components` of `PCA` to `0.95`. As the number is a float and not an integer, this tells SKLearn that we'd like PCA to reduce the number of column to those that contain 95% of the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303471,
     "status": "ok",
     "timestamp": 1661849890358,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "_o3UF2BGs5VL",
    "outputId": "eae96f66-8274-4fe7-d3d0-c1cb80f64116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 158.30231881141663 seconds ---\n",
      "81.27% accuracy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model_pipeline = make_pipeline(StandardScaler(),\n",
    "                               PCA(n_components=0.95),\n",
    "                               KNeighborsClassifier())\n",
    "\n",
    "param_grid = {\"kneighborsclassifier__n_neighbors\": list(range(3, 30)),\n",
    "              \"kneighborsclassifier__weights\":[\"uniform\", \"distance\"],\n",
    "              \"kneighborsclassifier__p\":[1,2]}\n",
    "\n",
    "neigh3_search = RandomizedSearchCV(model_pipeline,\n",
    "                                   param_grid,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   n_iter=50,\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=123)\n",
    "\n",
    "neigh3_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_95_pca = end_time - start_time\n",
    "best_score_95_pca = neigh3_search.best_score_\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time_taken_95_pca))\n",
    "print(f\"{round(best_score_95_pca * 100, 2)}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jM2mhpYO9uhZ"
   },
   "source": [
    "### Comparing the first 3 iterations\n",
    "Let's have a look at the differences in time and accuracy across our 3 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1661849890359,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "7nLwxzBw7xdF",
    "outputId": "9cc87d35-7118-4e2d-88d3-c4a39f10ab58"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>129.964527</td>\n",
       "      <td>0.80850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38.688080</td>\n",
       "      <td>0.29500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>158.302319</td>\n",
       "      <td>0.81275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time  accuracy\n",
       "pca_version                      \n",
       "None         129.964527   0.80850\n",
       "10            38.688080   0.29500\n",
       "0.95         158.302319   0.81275"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_data = {'pca_version': ['None', '10', '0.95'],\n",
    "                  'time': [time_taken_no_pca, time_taken_10_pca, time_taken_95_pca],\n",
    "                  'accuracy': [best_score_no_pca, best_score_10_pca, best_score_95_pca]}\n",
    "\n",
    "times_df = pd.DataFrame(variables_data)\n",
    "\n",
    "times_df.set_index('pca_version', inplace=True)\n",
    "\n",
    "times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-pYgkLKWipu"
   },
   "source": [
    "### Picking the number of components 3: cross validation\n",
    "\n",
    "It is also possible to place different values for PCA in your parameter search to ensure you get the best fit for your data. This may seem counter productive at first, as we are training many pca models, and therefore losing our time gains. However, if you are retraining a model, as you've added some extra data to the dataset, you would just use the previous best value of `n_components` and retrain the model without full cross validation, and therefore benefit from the time gains.\n",
    "\n",
    "First, let's look at how we would do the initial training with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114501,
     "status": "ok",
     "timestamp": 1661850004845,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "rMCKyC5Lp1Pb",
    "outputId": "8560be03-997b-45c8-cc23-6e5f9ea18951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 113.84715390205383 seconds ---\n",
      "81.4% accuracy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model_pipeline = make_pipeline(StandardScaler(),\n",
    "                               PCA(),\n",
    "                               KNeighborsClassifier())\n",
    "\n",
    "param_grid = {\"pca__n_components\": list(range(10, 310, 20)),\n",
    "              \"kneighborsclassifier__n_neighbors\": list(range(3, 30)),\n",
    "              \"kneighborsclassifier__weights\":[\"uniform\", \"distance\"],\n",
    "              \"kneighborsclassifier__p\":[1,2]}\n",
    "\n",
    "neigh4_search = RandomizedSearchCV(model_pipeline,\n",
    "                                   param_grid,\n",
    "                                   scoring=\"accuracy\",\n",
    "                                   n_iter=50,\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=123)\n",
    "\n",
    "neigh4_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_search_pca = end_time - start_time\n",
    "best_score_search_pca = neigh4_search.best_score_\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time_taken_search_pca))\n",
    "print(f\"{round(best_score_search_pca * 100, 2)}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHgK6HmXwvrK"
   },
   "source": [
    "Next, let's look at how quick it would be to retrain our model using the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1661850004846,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "oUTT0nHQskZV",
    "outputId": "0098d740-dfc5-48e7-aa26-4f55a3a7b40e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 250,\n",
       " 'kneighborsclassifier__weights': 'uniform',\n",
       " 'kneighborsclassifier__p': 2,\n",
       " 'kneighborsclassifier__n_neighbors': 27}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh4_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1701,
     "status": "ok",
     "timestamp": 1661850006532,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "3obd0sVjuFMf",
    "outputId": "2eae6d54-9450-4e00-a389-f3f8d2e5b27d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.0272536277770996 seconds ---\n",
      "85.58% accuracy\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model_pipeline = make_pipeline(StandardScaler(),\n",
    "                               PCA(n_components=250),\n",
    "                               KNeighborsClassifier(weights='uniform',\n",
    "                                                    p=2,\n",
    "                                                    n_neighbors=27))\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_retrain_pca = end_time - start_time\n",
    "best_score_retrain_pca = model_pipeline.score(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time_taken_retrain_pca))\n",
    "print(f\"{round(best_score_retrain_pca * 100, 2)}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb2Fk-f144S_"
   },
   "source": [
    "\n",
    "\n",
    "> **Note:** the uptick in accuracy for the retrained model is likely due to the fact that this is the only model not using cross validation. Remember, cross validation breaks the training data down into smaller chunks and uses each as a test set, then gives us the average accuracy of all tests. Here we just have the a non-averaged accuracy of a larger training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10s4oa25xCTs"
   },
   "source": [
    "### Comparing all 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1661850006537,
     "user": {
      "displayName": "Ben Elvin",
      "userId": "09111547648527423041"
     },
     "user_tz": -120
    },
    "id": "HQCJ5dpZxFzs",
    "outputId": "f36a96e8-97bf-4c42-f3d8-c0500d410886"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>129.964527</td>\n",
       "      <td>0.80850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38.688080</td>\n",
       "      <td>0.29500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>158.302319</td>\n",
       "      <td>0.81275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross validation</th>\n",
       "      <td>113.847154</td>\n",
       "      <td>0.81400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrain only</th>\n",
       "      <td>1.027254</td>\n",
       "      <td>0.85575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  accuracy\n",
       "pca_version                           \n",
       "None              129.964527   0.80850\n",
       "10                 38.688080   0.29500\n",
       "0.95              158.302319   0.81275\n",
       "Cross validation  113.847154   0.81400\n",
       "Retrain only        1.027254   0.85575"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_data = {'pca_version': ['None', '10', '0.95', 'Cross validation', 'Retrain only'],\n",
    "                  'time': [time_taken_no_pca, time_taken_10_pca, time_taken_95_pca, time_taken_search_pca, time_taken_retrain_pca],\n",
    "                  'accuracy': [best_score_no_pca, best_score_10_pca, best_score_95_pca, best_score_search_pca, best_score_retrain_pca]}\n",
    "\n",
    "times_df = pd.DataFrame(variables_data)\n",
    "\n",
    "times_df.set_index('pca_version', inplace=True)\n",
    "\n",
    "times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tofz_P91Wipw"
   },
   "source": [
    "## Practice: \n",
    "\n",
    "- Apply PCA to the Diamonds dataset.\n",
    "- Apply PCA to the Housing case study Pipeline.\n",
    "\n",
    "In both cases, tune the number of components and analyse whether the performance improves, stays stable or decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58Gm3YSAWipw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1jQg47jT5Z9JvGA5NpV-HPvgR-ZB5nIIo",
     "timestamp": 1675240795564
    },
    {
     "file_id": "1pCBKLtxsKgvCw81SmvnCMTXOmTN-vUew",
     "timestamp": 1661504046666
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
